DATA_DIR=/data
DB_DIR=/db
APP_DIR=/app
# === LLM provider selection ===
# openai | openrouter | ollama
LLM_PROVIDER=openai
# gpt-4o-mini | meta-llama/llama-3.1-70b-instruct:free | llama3.1
LLM_MODEL=gpt-4o-mini

# OpenAI
OPENAI_API_KEY=sk-...

# OpenRouter
OPENROUTER_API_KEY=or-...

# Ollama
# For the local API
OLLAMA_BASE_URL=http://host.docker.internal:11434

# === SQL safety ===
ROW_LIMIT=200
QUERY_TIMEOUT_MS=8000

# Prefect
PREFECT_API_URL=http://prefect:4200/api
PREFECT_LOGGING_LEVEL=INFO
WORK_QUEUE=default